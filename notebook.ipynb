{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMWnV5Rm3gJR4L6kUUBg4Wn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JacobAshoo/NNFS/blob/main/notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "TODO:\n",
        "-Import CIFAR10 dataset\n",
        "-prep data for training\n",
        "-training loop\n",
        "\n",
        "\n",
        "\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "C9KatraL7NLo",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "daa801cb-d8a9-4577-b909-9126f2194f40"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nTODO:\\n-Droput\\n-Import CIFAR10 dataset\\n-prep data for training\\n-training loop\\n\\n\\n\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torchvision\n",
        "import pickle\n",
        "from sklearn.preprocessing import OneHotEncoder"
      ],
      "metadata": {
        "id": "T-Q862boZl9J"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Relu:\n",
        "  def __init__(self):\n",
        "    pass\n",
        "\n",
        "  def __call__(self, x):\n",
        "    self.x = x\n",
        "    return torch.maximum(x, torch.tensor(0.0, device=x.device))\n",
        "\n",
        "  def backward(self, grad):\n",
        "    return grad * (self.x > 0).float()\n",
        "\n",
        "class Softmax:\n",
        "  def __init__(self):\n",
        "    pass\n",
        "\n",
        "  def __call__(self, x):\n",
        "    exp_x = torch.exp(x - torch.max(x, dim=1, keepdim=True).values)\n",
        "    self.softmax_out = exp_x / torch.sum(exp_x, dim=1, keepdim=True)\n",
        "    return self.softmax_out\n",
        "\n",
        "  def backward(self, grad):\n",
        "    batch_size, num_classes = self.softmax_out.shape\n",
        "    jacobian = torch.zeros(batch_size, num_classes, num_classes, device=grad.device)\n",
        "    for i in range(num_classes):\n",
        "      for j in range(num_classes):\n",
        "        if i == j:\n",
        "          jacobian[:, i, j] = self.softmax_out[:, i] * (1 - self.softmax_out[:, i])\n",
        "        else:\n",
        "          jacobian[:, i, j] = -self.softmax_out[:, i] * self.softmax_out[:, j]\n",
        "    return torch.bmm(jacobian, grad.unsqueeze(-1)).squeeze(-1)\n"
      ],
      "metadata": {
        "id": "_Q0ry4SqY1lG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CrossEntropy:\n",
        "  def __init__(self):\n",
        "    pass\n",
        "\n",
        "  def __call__(self, ypred, y, l2_reg=False, l=0.01, weights=[]):\n",
        "    self.l2_reg = l2_reg\n",
        "    self.l = l\n",
        "    self.weights = weights\n",
        "    ypred = torch.clamp(ypred, min=1e-9)\n",
        "    loss = -torch.mean(torch.sum(y * torch.log(ypred), dim=1))\n",
        "    if l2_reg and weights:\n",
        "      loss += (l / 2) * sum(torch.sum(w ** 2) for w in weights)\n",
        "    return loss\n",
        "\n",
        "  def backward(self, ypred, y):\n",
        "    grad_output = -y / ypred\n",
        "    if self.l2_reg and self.weights:\n",
        "      for w in self.weights:\n",
        "        grad_output += self.l * w\n",
        "    return grad_output"
      ],
      "metadata": {
        "id": "ATe5r3z4qHY5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9SJZW5TCYXNV"
      },
      "outputs": [],
      "source": [
        "class Linear:\n",
        "  def __init__(self, input_size, output_size, activation, device=None, dropout=1.0):\n",
        "    self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu') if device is None else device\n",
        "    self.input_size = input_size\n",
        "    self.output_size = output_size\n",
        "    self.w = torch.randn(output_size, input_size, device=self.device, requires_grad=True) * 0.01\n",
        "    self.b = torch.zeros(output_size, device=self.device, requires_grad=True)\n",
        "    self.activation = activation\n",
        "    self.dropout = dropout\n",
        "\n",
        "  def __call__(self, x, training=True):\n",
        "    self.x = x.to(self.device)\n",
        "    self.z = torch.matmul(self.x, self.w.T) + self.b\n",
        "    self.a = self.activation(self.z)\n",
        "\n",
        "\n",
        "    if training and self.dropout < 1.0:\n",
        "      mask = (torch.rand(self.a.shape, device=self.device) < self.dropout).float()\n",
        "      self.a *= mask\n",
        "      self.a /= self.dropout\n",
        "\n",
        "    return self.a\n",
        "\n",
        "  def backward(self, grad):\n",
        "    grad = self.activation.backward(grad)\n",
        "    dw = torch.matmul(grad.T, self.x)\n",
        "    db = torch.sum(grad, dim=0)\n",
        "    dx = torch.matmul(grad, self.w)\n",
        "    return dx, dw, db"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class FCNN:\n",
        "  def __init__(self, input_size, output_size, dropout=False):\n",
        "    self.l1 = Linear(input_size, 10, Relu())\n",
        "    self.l2 = Linear(10, output_size, Softmax())\n",
        "    self.layers = [self.l1, self.l2]\n",
        "\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.l1(x)\n",
        "    x = self.l2(x)\n",
        "    return x\n",
        "\n",
        "  def __call__(self, x):\n",
        "    return self.forward(x)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "_gN-0fQpaih4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = torchvision.datasets.CIFAR10(root=\"/content\",download=True)\n",
        "\n",
        "xs = []\n",
        "labels = []\n",
        "\n",
        "for i in range(1,6):\n",
        "  with open(f\"/content/cifar-10-batches-py/data_batch_{i}\", 'rb') as f:\n",
        "    dict = pickle.load(f, encoding='bytes')\n",
        "    xs.append(dict[b'data'])\n",
        "    labels += dict[b'labels']\n",
        "\n",
        "\n",
        "labels = np.array(labels).reshape(-1,1)\n",
        "encoder = OneHotEncoder(sparse_output=False)\n",
        "y = encoder.fit_transform(labels)\n",
        "\n",
        "xs = np.array(xs)\n",
        "\n",
        "x = xs.reshape(50000, 3072) / 255\n",
        "\n",
        "print(x.shape)\n",
        "print(y.shape)\n",
        "\n",
        "print(x[0])\n",
        "print(y[0])\n",
        "\n",
        "\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OaZtRznWPE8F",
        "outputId": "d930a291-57a2-4b2f-c303-cd5d6be0ca73"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "(50000, 3072)\n",
            "(50000, 10)\n",
            "[0.23137255 0.16862745 0.19607843 ... 0.54901961 0.32941176 0.28235294]\n",
            "[0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(42)\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using {device}\")\n",
        "\n",
        "model = FCNN(10, 3)\n",
        "\n",
        "x = torch.randn(1, 10, device=device) * 0.01\n",
        "y = torch.tensor([[1,0,0]], device=device)\n",
        "loss_function = CrossEntropy();\n",
        "ypred = model(x)\n",
        "\n",
        "print(ypred)\n",
        "loss = loss_function(ypred, y)\n",
        "print(loss)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KZ28sDhHitJL",
        "outputId": "5dca4f74-2181-4ead-8802-ac31437adf60"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cpu\n",
            "tensor([[0.3416, 0.3423, 0.3161]], grad_fn=<MulBackward0>)\n",
            "tensor(1.0741, grad_fn=<NegBackward0>)\n"
          ]
        }
      ]
    }
  ]
}